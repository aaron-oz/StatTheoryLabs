---
title: "Getting Started on the Project - Nonparametric Tests and Their Power"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(tidyverse)
library(gradethis)
tutorial_options(
  # use gradethis for checking
  exercise.checker = gradethis::grade_learnr
  )
knitr::opts_chunk$set(echo = FALSE)
set.seed(113877)
simulated_data <- data.frame(
  x = rnorm(n = 100, mean = 5, sd = 1)
)
simulated_data <- simulated_data %>%
  mutate(
    y =  rnorm(n = 100, mean = 5, sd = .74)
  )

sim.dataset <- function(n, mean_vals, sd_vals) {
  # Simulate X variable:
  simulated_data <- data.frame(
    x = rnorm(n = n, mean = mean_vals[1], sd = sd_vals[1])
  )
  # Simulate Y variable:
  simulated_data <- simulated_data %>%
    mutate(
      y = rnorm(n = n, mean = mean_vals[2], sd = sd_vals[2])
    )
  # Return dataset
  return(simulated_data)
}


power.val <- data.frame(
  pval_param = rep(NA, 500),
  pval_nonparam = rep(NA, 500)
  )

```

## Getting Started - Some New Packages

The `tidyverse` is a suite of packages that will help us work with data. Depending on which test your project is focused on, you may need to use another package that has the test implemented.

```{r packages, exercise = T}
library(tidyverse)
```


## Simulating A Simple Dataset 

The `head` function shows the first 6 rows of the dataframe, so that we can peak and see what our new data looks like. The `dim` function tells us the dimensions of the object. This can come in handy for checking that we have something with the dimensions we expect (like here we said `n=100` so we should end up with something that has 100 rows).

**Generate data for one group**

```{r simDat, exercise = T}
simulated_data <- data.frame(
  x = rnorm(n = 100, mean = 5, sd = 1)
)
head(simulated_data)
dim(simulated_data)
```

**Generate data for another group**

The `%>%` operator is called the **piping** operator. It takes the output of the previous expression and pipes it into the first argument of the function in the following one. 
To continue our analogy with mathematical functions, `x %>% f(y)` is equivalent to `f(x, y)`.

**A note on piping:** Note that we can read these two lines of code as the following: *"Take the `simulated_data` dataset and **pipe** it into the `mutate` function. 
Mutate the `simulated_data` data set by creating a new variable called `y` that is another random draw from a normal distribution.

Then assign the resulting dataset to the object called `simulated_data`, i.e. overwrite the old `simulated_data` dataset with the new one containing the new variable."*


```{r simDat2, exercise = T}
simulated_data <- simulated_data %>%
  mutate(
    y =  rnorm(n = 100, mean = 5, sd = .74)
  )
head(simulated_data)
dim(simulated_data)
```

**Plot our data**

Up until now, we have been making simple plots, but now we will want more professional looking graphs.

With `ggplot()`:

- The first argument is always the dataset. 
- Next, you provide the variables from the dataset to be assigned to `aes`thetic elements of the plot, e.g. the x and the y axes. 
- Finally, you use another layer, separated by a `+` to specify the `geom`etric object for the plot. Since we want to scatterplot, we use `geom_point()`.

For instance, if you wanted to visualize the scatterplot below using a line graph, you would replace `geom_point()` with `geom_line()`.


```{r plot, exercise = T}
ggplot(simulated_data, aes(x, y)) + 
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Informative X label here", y = "Informative Y label here") +
  ggtitle("Informative title here") +
  theme_minimal(base_size = 20)

ggplot(simulated_data, aes(x)) + 
  geom_histogram() +
  labs(x = "Informative X label here") +
  ggtitle("Informative title here") +
  theme_minimal(base_size = 20)

ggplot(simulated_data, aes(y)) + 
  geom_histogram() +
  labs(x = "Informative X label here") +
  ggtitle("Informative title here") +
  theme_minimal(base_size = 20)
```


## Function - Simulate Data

We will want to do this many times in a simulation study, so we should wrap this code into functions that we can call multiple times. 

```{r func, exercise = T}
sim.dataset <- function(n, mean_vals, sd_vals) {
  # Simulate X variable:
  simulated_data <- data.frame(
    x = rnorm(n = n, mean = mean_vals[1], sd = sd_vals[1])
  )
  # Simulate Y variable:
  simulated_data <- simulated_data %>%
    mutate(
      y = rnorm(n = n, mean = mean_vals[2], sd = sd_vals[2])
    )
  # Return dataset
  return(simulated_data)
}

## Note: your sim.dataset might look different, perhaps you won't want rnorm for example or you want differing sample sizes.
```

Let's try it out! We call the function we just wrote, plugging in the expected parameters, and save the output to `test_dataset`.

```{r testF, exercise = T}
test_dataset <- sim.dataset(n = 150, mean_vals = c(0,5), sd_vals = c(1,1))

ggplot(test_dataset, aes(x)) + 
  geom_histogram()+
  labs(x = "Informative X label here") +
  ggtitle("Informative title here") +
  theme_minimal(base_size = 20)

ggplot(test_dataset, aes(y)) + 
  geom_histogram()+
  labs(x = "Informative X label here") +
  ggtitle("Informative title here") +
  theme_minimal(base_size = 20)

```


## Many Simulations via Loops

We'll need to create a dataframe to store our results.

```{r storage, exercise = T}
power.val <- data.frame(
  pval_param = rep(NA, 500),
  pval_nonparam = rep(NA, 500)
  )
head(power.val)
dim(power.val)
```

This project takes the place of an exam on Hypothesis Tests. We will learn about the theory behind them and talk about a property of them called power. To have enough of a big picture understanding to get started, be sure to read the [Wiki page](https://en.wikipedia.org/wiki/Power_of_a_test) up to and including the "Interpretation" section.

Here we have chosen our $\alpha$ to be 0.05. If the p-value for the coefficient is less than $\alpha$ we will reject the null hypothesis.

```{r firstSim, exercise = T}
#Note: you can't run this until you fill in things where the ## are


significance_value <- 0.05

for (dataset.i in 1:500) {
  simulated_df <- sim.dataset(n = 150, mean_vals = c(0,5), sd_vals = c(1,1))
  res_param = ## replace with your parametric test
  res_nonparam = ## replace with your nonparametric test
  power.val$pval_param[dataset.i] <- ## res_param's pvalue
                                          < significance_value
  power.val$pval_nonparam[dataset.i] <- ## res_nonparam's pvalue
                                            < significance_value
}
table(power.val$pval_param)
table(power.val$pval_nonparam)
```

We can get a quick sense of how many times (out of 500) each test was rejected (TRUE).

## Function - Get Power

```{r funcP, exercise = T}
#Note: you can't run this until you fill in things where the ## are

## Because simulate.power is not yet defined, the rest of the tutorial will not be runnable until this is changed. I provide a template for you to walk through this on your own for your own scenario. Here we just want to make sure we understand the structure (else go through code annotation steps).


simulate.power <- function(n.sims, n, mean_vals, sd_vals) {
  
  # Dataframe to hold results:
  power.val <- data.frame(
  pval_param = rep(NA, n.sims),
  pval_nonparam = rep(NA, n.sims)
  )
  
  # Simulating many tests:
  for (dataset.i in 1:n.sims) {
    simulated_df <- sim.dataset(n = n, mean_vals = mean_vals, sd_vals = sd_vals)
    res_param <- ## replace with your parametric test
    res_nonparam <- ## replace with your nonparametric test
    power.val$pval_param[dataset.i] <- ## res_param's pvalue
                                          < significance_value
    power.val$pval_nonparam[dataset.i] <- ## res_nonparam's pvalue
                                            < significance_value
  }
  
  # Aggregating into summary 
  power.val <- summarise(power.val,
                          param.power = mean(pval_param),
                          nonparam.power = mean(pval_nonparam))
  
  # Returning a summary dataframe
  return(power.val)
}
```

To call this function:

```{r, power, exercise = T}
simulate.power(n.sims = 500,
               n = 100, 
               mean_vals = c(0,5), sd_vals = c(1,1))
```


## Outline of a Simulation Study - Changing One Parameter

There is inherent randomness in a simulation study. This is not ideal as your answers would have to change each time you reran code. By "setting a seed" at the start of your study you tell the random number generator where to start in its sequence of random numbers (so you'll get the same answer each time you rerun the code in the same order). You can think of the number you pick for `set.seed()` as a bookmark for the sampling algorithm. Setting the seed also ensures others can reproduce your work.

Talking more about this is beyond the scope of the class, but if you are interested, I point you to Kellie Ottoboni's cool work on [sampling in R](http://www.kellieottoboni.com/posts/2019/01/random-problems-with-r/).

```{r outline, exercise = T}
set.seed(721226) ## set seed so your findings are reproducible
num_reps <- 500 ## turn into a variable so we can easily change it
sample_size <- 100 ## turn into a variable so we can easily change it
second_mean <- c(0, 0.1, 0.5, 1) ## possible scenarios
num_levels <- length(second_mean) ## how many scenarios
## create a space to store power from each scenario
sim_study_output <- data.frame(
  pval_param = rep(NA, num_levels),
  pval_nonparam = rep(NA, num_levels),
  true_mean = second_mean
)
```

```{r, outline1b-setup}
set.seed(721226) ## set seed so your findings are reproducible
num_reps <- 500 ## turn into a variable so we can easily change it
sample_size <- 100 ## turn into a variable so we can easily change it
second_mean <- c(0, 0.1, 0.5, 1) ## possible scenarios
num_levels <- length(second_mean) ## how many scenarios
## create a space to store power from each scenario
sim_study_output <- data.frame(
  pval_param = rep(NA, num_levels),
  pval_nonparam = rep(NA, num_levels),
  true_mean = second_mean
)
```




```{r, outline1b, exercise = T}
for (i in 1:num_levels) {
  sim_study_output[i, 1:2] <- simulate.power(
    n.sims = num_reps,
    n = sample_size,
    mean_vals = c(0, second_mean[i]), sd_vals = c(1,1)
  )
  ## only override first two columns with power values
  ## same scenario except each time we change the mean of the second dataset
}

sim_study_output

ggplot(sim_study_output, aes(x = true_mean, y = param.power)) +
  geom_point() +
  geom_line() +
  labs(x = "Second Mean", y = "Power (alpha = 0.05)") +
  ggtitle("Power of Parametric Test \n Varying Difference From First Mean (0)") +
  theme_minimal(base_size = 20)

ggplot(sim_study_output, aes(x = true_mean, y = nonparam.power)) +
  geom_point() +
  geom_line() +
  labs(x = "Second Mean", y = "Power (alpha = 0.05)") +
  ggtitle("Power of Nonparametric Test \n Varying Difference From First Mean (0)") +
  theme_minimal(base_size = 20)
# \n is a line break
```

We can plot the power as a function of the second mean.

If we want these on the same plot we have to rearrange the data a little bit ("tidy" it) and then make a new plot. 

**Extra credit opportunity**: Write the code to put `param.power` and `nonparam.power` results in the same plot taking advantage of functions `pivot_wider` and/or `pivot_longer` (see [here](https://github.com/rstudio/cheatsheets/raw/master/tidyr.pdf) for more details).

## Outline of a Simulation Study - Changing Two Parameters

What if we want to change two parameters. Now we need all combinations of pairs of parameters. This can add up quickly so be strategic about the combinations you are interested in.

```{r outline2, exercise = T}
set.seed(721226) ## set seed so your findings are reproducible
num_reps <- 500 ## turn into a variable so we can easily change it
sample_size <- c(50, 100, 150) ## possible scenarios
second_mean <- c(0, 0.1, 0.5, 1) ## possible scenarios
num_levels <- length(second_mean) * length(sample_size) ## how many scenarios
all_scenarios <- expand.grid(sample_size = sample_size, second_mean = second_mean)
## get all possible combinations of these two parameters
head(all_scenarios)
dim(all_scenarios)
## create a space to store power from each scenario
sim_study_output <- data.frame(
  pval_param = rep(NA, num_levels),
  pval_nonparam = rep(NA, num_levels),
  true_mean = as.factor(second_mean),
  sample_size = as.factor(sample_size)
)
## the as.factor lets R know that we want this to be a category, useful for plotting later
```

```{r, outline2b-setup}
set.seed(721226) ## set seed so your findings are reproducible
num_reps <- 500 ## turn into a variable so we can easily change it
sample_size <- c(50, 100, 150) ## possible scenarios
second_mean <- c(0, 0.1, 0.5, 1) ## possible scenarios
num_levels <- length(second_mean) * length(sample_size) ## how many scenarios
all_scenarios <- expand.grid(sample_size = sample_size, second_mean = second_mean)
## get all possible combinations of these two parameters
head(all_scenarios)
dim(all_scenarios)
## create a space to store power from each scenario
sim_study_output <- data.frame(
  pval_param = rep(NA, num_levels),
  pval_nonparam = rep(NA, num_levels),
  true_mean = as.factor(second_mean),
  sample_size = as.factor(sample_size)
)
```

Now we are interested in the relationship between sample size and power for different mean scenarios. We can plot the power as a function of the sample size and denote the scenarios with different colors.


```{r, outline2b, exercise = T}
for (i in 1:num_levels) {
  sim_study_output[i, 1:2] <- simulate.power(
    n.sims = num_reps,
    n = all_scenarios$sample_size[i],
    mean_vals = c(0, second_mean[i]), sd_vals = c(1,1)
  )
  ## only overwrite the first two columns
  ## same scenario except each time we change second mean and sample size
}
sim_study_output
ggplot(sim_study_output, aes(x = sample_size, y = param.power, col = mean_vals)) +
  geom_point() +
  geom_line() +
  labs(x = "Sample Size", y = "Power (alpha = 0.05)") +
  ggtitle("Power of Parametric Test \n When Varying Second Mean \n and Sample Size") +
  theme_minimal(base_size = 20)
## the \n adds a line break in the title

ggplot(sim_study_output, aes(x = sample_size, y = nonparam.power, col = mean_vals)) +
  geom_point() +
  geom_line() +
  labs(x = "Sample Size", y = "Power (alpha = 0.05)") +
  ggtitle("Power of Nonparametric Test \n When Varying Second Mean \n and Sample Size") +
  theme_minimal(base_size = 20)
```

## Outline of a Simulation Study - Changing Three Parameters

What if we want to change three parameters? Now we need all combinations of triplets of parameters. Again this can add up quickly so be strategic about the combinations you are interested in. To do 500 replications for 27 scenarios takes about a minute and a half. Here we will cut down the number of replications to 100, so we have to wait less than 30 seconds.

```{r outline3, exercise = T}
set.seed(721226) ## set seed so your findings are reproducible
num_reps <- 100 ## turn into a variable so we can easily change it
sample_size <- c(50, 100, 150) ## possible scenarios
second_mean <- c(0, 0.5, 1) ## possible scenarios
second_sd <- c(1, 0.2, 2)
num_levels <- length(second_mean) * length(sample_size) * length(second_sd) ## how many scenarios
all_scenarios <- expand.grid(sample_size = sample_size, second_mean = second_mean, second_sd = second_sd)
## get all possible combinations of these two parameters
head(all_scenarios)
dim(all_scenarios)
## create a space to store power from each scenario
sim_study_output <- data.frame(
  pval_param = rep(NA, num_levels),
  pval_nonparam = rep(NA, num_levels),
  true_mean = as.factor(second_mean),
  true_sd = as.factor(second_sd),
  sample_size = as.factor(sample_size)
)
## the as.factor lets R know that we want this to be a category, useful for plotting later
```

```{r outline3b-setup}
set.seed(721226) ## set seed so your findings are reproducible
num_reps <- 100 ## turn into a variable so we can easily change it
sample_size <- c(50, 100, 150) ## possible scenarios
second_mean <- c(0, 0.5, 1) ## possible scenarios
second_sd <- c(1, 0.2, 2)
num_levels <- length(second_mean) * length(sample_size) * length(second_sd) ## how many scenarios
all_scenarios <- expand.grid(sample_size = sample_size, second_mean = second_mean, second_sd = second_sd)
## get all possible combinations of these two parameters
head(all_scenarios)
dim(all_scenarios)
## create a space to store power from each scenario
sim_study_output <- data.frame(
  pval_param = rep(NA, num_levels),
  pval_nonparam = rep(NA, num_levels),
  true_mean = as.factor(second_mean),
  true_sd = as.factor(second_sd),
  sample_size = as.factor(sample_size)
)
## the as.factor lets R know that we want this to be a category, useful for plotting later
```


```{r outline3b, exercise = T}
for (i in 1:num_levels) {
  sim_study_output[i, 1:2] <- simulate.power(
    n.sims = num_reps,
    n = all_scenarios$sample_size[i],
    mean_vals = c(0, second_mean[i]), sd_vals = c(1,second_sd[i])
  )
  ## only overwrite the first two columns
  ## same scenario except each time we change second mean, second sd, sample size
}
sim_study_output
ggplot(sim_study_output, aes(x = sample_size, y = param.power, col = true_mean)) +
  geom_point() +
  geom_line() +
  facet_wrap(~true_sd) +
  labs(x = "Sample Size", y = "Power (alpha = 0.05)") +
  ggtitle("Power When Varying Second Mean, Second SD, \n and Sample Size") +
  theme_minimal(base_size = 20)
## the \n adds a line break in the title
## the facet_wrap makes a different plot of the same form for each of the specified categories

ggplot(sim_study_output, aes(x = sample_size, y = nonparam.power, col = true_mean)) +
  geom_point() +
  geom_line() +
  facet_wrap(~true_sd) +
  labs(x = "Sample Size", y = "Power (alpha = 0.05)") +
  ggtitle("Power When Varying Second Mean, Second SD, \n and Sample Size") +
  theme_minimal(base_size = 20)
```

Now we are interested in the relationship between sample size and power for different scenarios that vary on two other parameters. We can plot the power as a function of the sample size and denote the scenarios with different colors and across multiple panels or "facets".

## Project Preview

Each student will use the same number of replications, the same baseline mean and standard deviation for normal distributions, the same sample sizes (multiple, across x-axis in result plots), and the same number of levels of misspecification (multiple, facets in result plots). You will be responsible for specifying what those misspecification levels look like. The variability may take different forms based on your scenario (i.e. if you aren't working with normal distributions).

## Your Immediate Tasks

Tomorrow will be a work day on the project. Before the next Project checkpoint (evening session, October 7th), you are responsible for completing the following:

- Make sure you understand the code chunks in this tutorial as they will provide the skeleton of your own simulation study. You may want to go through the Code Annotation process (described below for reference) for some of the more complicated code chunks (especially those that write and use functions in loops). 

- Read the [Wiki page](https://en.wikipedia.org/wiki/Power_of_a_test) about Power up to and including the "Interpretation" section.

- Understand the null and alternative hypotheses for your two tests (a parametric and nonparametric test). They will have the same set.

- Understand how to use your two functions (a parametric and nonparametric test). This means understanding inputs (what form of data do they expect), outputs (how do you get what you need out of them), and other tuning parameters (which should you use for your study).

- Understand the assumptions that your tests are making. These will help inform what scenarios are "interesting" and worth exploring in your simulation study (i.e. you may want to break an assumption and see how they perform when compared to how they perform in ideal conditions).

- Come talk to me in office hours if you have questions about any of the above. Progress will be hindered if there is still confusion about these moving forward.

- **Extra credit opportunity**: Write the code to put `param.power` and `nonparam.power` results in the same plot taking advantage of functions `pivot_wider` and/or `pivot_longer` (see [here](https://github.com/rstudio/cheatsheets/raw/master/tidyr.pdf) for more details). This code must have a working example to be considered, not just a code sketch. 


**Annotating Code**

1. Do an initial reading of each code chunk. Note any questions that pop into your head. If you do this inline, use a hashtag (#) to add a comment.

2. Identify any functions you do not understand and look them up using the help function `help(function_name)` or the "Help" tab in the bottom right pane. Make sure you understand the input paramters and the form of the output. 

3. Identify any overall structure. Is a subtask repeated multiple times? How many times?

4. For each object, predict their size. Check your intuition using `dim` or `length`. You may also want to use `class` to identify the type of an object.

5. Write a one to two sentence description of what the code chunk does that someone without a coding background could understand.



* * *

This lab adapts some power materials from [A. Hales](https://osf.io/rzbyj/) and coding instruction from various Open Intro labs and was adapted and learnr-ified by S. Stoudt.