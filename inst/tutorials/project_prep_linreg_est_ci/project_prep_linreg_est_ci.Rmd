---
title: "Getting Started on the Project - - Linear Regression Slope Estimation and CI Coverage"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(learnrhash)
library(tidyverse)
library(gradethis)
library(broom)
tutorial_options(
  # use gradethis for checking
  exercise.checker = gradethis::grade_learnr
  )
knitr::opts_chunk$set(echo = FALSE)
set.seed(113877)

simulated_data <- data.frame(
  x = rnorm(n = 100, mean = 5, sd = 1)
)

# Creating Dependent variable
simulated_data <- simulated_data %>% 
  mutate(
    y = 2.80 + 0.21*x + rnorm(n = 100, mean = 0, sd = 0.74)
    ) 

sim.dataset <- function(n, b0, b1, residual_se) {

  # Simulate X variable:
  simulated_data <- data.frame(
    x = rnorm(n = n, mean = 5, sd = 1)
  )

  # Simulate Y variable:
  simulated_data <- simulated_data %>%
    mutate(
      y = b0 + (b1 * x) + rnorm(n = n, mean = 0, sd = residual_se)
    )

  # Return dataset
  return(simulated_data)
}

simulate.est <- function(n.sims, n, b0, b1, residual_se) {

  # Dataframe to hold results:
  coef.est <- data.frame(
    est.b1 = rep(NA, n.sims),
    cover.b1 = rep(NA, n.sims)
  )

  # Simulating many tests:
  for (dataset.i in 1:n.sims) {
    simulated_df <- sim.dataset(n = n, b0 = b0, b1 = b1, residual_se = residual_se)
    model <- tidy(lm(y ~ x, data = simulated_df))
    t_star <- qt(0.975, df = n - 2)
    coef.est$est.b1[dataset.i] <- model$estimate[2]
    coef.est$cover.b1[dataset.i] <- ((model$estimate[2] - t_star * model$std.error[2]) < b1 &
                                       b1 < (model$estimate[2] + t_star * model$std.error[2]))
  }

  # Aggregating into summary
  coef.est <- summarise(coef.est,
    b1.est = mean(est.b1),
    b1.cover = mean(cover.b1)
  )

  # Returning a summary dataframe
  return(coef.est)
}
coef.est <- data.frame(
  est.b1 = rep(NA, 500),
  cover.b1 = rep(NA, 500)
)

```

## Getting Started - Some New Packages

The `tidyverse` is a suite of packages that will help us work with data. The `broom` package helps us clean up regression output.

```{r packages, exercise = T}
library(tidyverse)
library(broom)
```


## Simulating A Simple Dataset 

The `head` function shows the first 6 rows of the dataframe, so that we can peak and see what our new data looks like. The `dim` function tells us the dimensions of the object. This can come in handy for checking that we have something with the dimensions we expect (like here we said `n=100` so we should end up with something that has 100 rows).

**Generate an explanatory variable**

```{r simDat, exercise = T}
simulated_data <- data.frame(
  x = rnorm(n = 100, mean = 5, sd = 1)
)
head(simulated_data)
dim(simulated_data)
```

**Generate the response variable based on the explanatory variable**

The `%>%` operator is called the **piping** operator. It takes the output of the previous expression and pipes it into the first argument of the function in the following one. 
To continue our analogy with mathematical functions, `x %>% f(y)` is equivalent to `f(x, y)`.

**A note on piping:** Note that we can read these two lines of code as the following: *"Take the `simulated_data` dataset and **pipe** it into the `mutate` function. 
Mutate the `simulated_data` data set by creating a new variable called `y` that is a linear combination of `x`. 

Then assign the resulting dataset to the object called `simulated_data`, i.e. overwrite the old `simulated_data` dataset with the new one containing the new variable."*
  
This is equivalent to going through each row, performing the linear combination, and recording that value in a new column called `y`.

```{r simDat2, exercise = T}
simulated_data <- simulated_data %>%
  mutate(
    y = 2.80 + 0.21 * x + rnorm(n = 100, mean = 0, sd = 0.74)
  )

head(simulated_data)
dim(simulated_data)
```

**Plot our data**

Up until now, we have been making simple plots, but now we will want more professional looking graphs.

With `ggplot()`:

- The first argument is always the dataset. 
- Next, you provide the variables from the dataset to be assigned to `aes`thetic elements of the plot, e.g. the x and the y axes. 
- Finally, you use another layer, separated by a `+` to specify the `geom`etric object for the plot. Since we want to scatterplot, we use `geom_point()`.

For instance, if you wanted to visualize the above plot using a line graph, you would replace `geom_point()` with `geom_line()`.


```{r plot, exercise = T}
ggplot(simulated_data, aes(x, y)) + 
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Informative X label here", y = "Informative Y label here") +
  ggtitle("Informative title here") +
  theme_minimal(base_size = 20)
```

**Fit a simple linear regression model**

The first argument in the function `lm` is a formula that takes the form 
`y ~ x`. Here it can be read that we want to make a linear model of 
`ye` as a function of `x`. The second argument specifies that R should look in the `simulated_data` data frame to find the two variables. 

The output of `lm` is an object that contains all of the information we need 
about the linear model that was just fit. We can access this information using 
the summary function.

```{r reg, exercise = T}
summary(
  lm(y ~ x, data = simulated_data)
)
```

Let's consider this output piece by piece. First, the formula used to describe 
the model is shown at the top. After the formula you find the five-number 
summary of the residuals. The "Coefficients" table shown next is key; its first 
column ("Estimate") displays the linear model's y-intercept and the coefficient of `x`. The fourth column ("Pr(>|t|)") shows the p-value for the hypothesis test whose null is that the corresponding coefficient is zero. 


## Function - Simulate Data

We will want to do this many times in a simulation study, so we should wrap this code into functions that we can call multiple times. 

```{r func, exercise = T}
sim.dataset <- function(n, b0, b1, residual_se) {

  # Simulate X variable:
  simulated_data <- data.frame(
    x = rnorm(n = n, mean = 5, sd = 1)
  )

  # Simulate Y variable:
  simulated_data <- simulated_data %>%
    mutate(
      y = b0 + (b1 * x) + rnorm(n = n, mean = 0, sd = residual_se)
    )

  # Return dataset
  return(simulated_data)
}
```

Let's try it out! We call the function we just wrote, plugging in the expected parameters, and save the output to `test_dataset`.

```{r testF, exercise = T}
test_dataset <- sim.dataset(n = 150, b0 = 2.80, b1 = 0.21, residual_se = 0.74)

ggplot(test_dataset, aes(x, y)) + 
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Informative X label here", y = "Informative Y label here") +
  ggtitle("Informative title here") +
  theme_minimal(base_size = 20)

summary(lm(y ~ x, data = test_dataset))
```


## Many Simulations via Loops

We'll need to create a dataframe to store our results.

```{r storage, exercise = T}
coef.est <- data.frame(
  est.b1 = rep(NA, 500),
  cover.b1 = rep(NA, 500)
)

head(coef.est)
dim(coef.est)
```

Note the `tidy` function helps us pull out the quantities of interest from the model summary. 

Here we have chosen our $\alpha$ to be 0.05. If the p-value for the coefficient is less than $\alpha$ we will reject the null hypothesis that the coefficient is equal to zero. 

```{r firstSim, exercise = T}
for (dataset.i in 1:500) {
  simulated_df <- sim.dataset(n = 100, b0 = 2.80, b1 = .21, residual_se = .76)
  model <- tidy(lm(y ~ x, data = simulated_df))
  t_star <- qt(0.975, df = n - 2)
  coef.est$est.b1[dataset.i] <- model$est[2]
  coef.est$cover.b1[dataset.i] <- ((model$est - t_star * model$std.error[2]) < b1 &
    b1 < (model$est + t_star * model$std.error[2]))
}

summary(coef.est$est.b1)

table(coef.est$cover.b1)
```

We can get a quick sense of how accurate our estimates and whether our confidence intervals for that estimate have the expected coverage (i.e. how many times (out of 500) did the confidence interval contain the truth `c`over.b = TRUE`).

## Function - Get Estimates and Confidence Intervals

```{r funcE, exercise = T}
simulate.est <- function(n.sims, n, b0, b1, residual_se) {

  # Dataframe to hold results:
  coef.est <- data.frame(
    est.b1 = rep(NA, n.sims),
    cover.b1 = rep(NA, n.sims)
  )

  # Simulating many tests:
  for (dataset.i in 1:n.sims) {
    simulated_df <- sim.dataset(n = n, b0 = b0, b1 = b1, residual_se = residual_se)
    model <- tidy(lm(y ~ x, data = simulated_df))
    t_star <- qt(0.975, df = n - 2)
    coef.est$est.b1[dataset.i] <- model$estimate[2]
    coef.est$cover.b1[dataset.i] <- ((model$estimate[2] - t_star * model$std.error[2]) < b1 &
                                       b1 < (model$estimate[2] + t_star * model$std.error[2]))
  }

  # Aggregating into summary
  coef.est <- summarise(coef.est,
    b1.est = mean(est.b1),
    b1.cover = mean(cover.b1)
  )

  # Returning a summary dataframe
  return(coef.est)
}

```

Let's test this one out too!

```{r, est, exercise = T}
simulate.est(n.sims = 500,
               n = 100, 
               b0 = 2.80, b1 = 0.21, residual_se = 0.74)

simulate.est(n.sims = 500,
               n = 250, 
               b0 = 2.80, b1 = 0.21, residual_se = 0.74)
```


## Outline of a Simulation Study - Changing One Parameter

There is inherent randomness in a simulation study. This is not ideal as your answers would have to change each time you reran code. By "setting a seed" at the start of your study you tell the random number generator where to start in its sequence of random numbers (so you'll get the same answer each time you rerun the code in the same order). You can think of the number you pick for `set.seed()` as a bookmark for the sampling algorithm. Setting the seed also ensures others can reproduce your work.

Talking more about this is beyond the scope of the class, but if you are interested, I point you to Kellie Ottoboni's cool work on [sampling in R](http://www.kellieottoboni.com/posts/2019/01/random-problems-with-r/).

Be patient. This has to go through 500*4 linear regressions.

```{r outline, exercise = T}
set.seed(721226) ## set seed so your findings are reproducible

num_reps <- 500 ## turn into a variable so we can easily change it
sample_size <- 100 ## turn into a variable so we can easily change it

b1.truth <- c(0.1, 0.2, 0.5, 1) ## possible scenarios

num_levels <- length(b1.truth) ## how many scenarios

## create a space to store power from each scenario
sim_study_output <- data.frame(
  b1.est = rep(NA, num_levels),
  b1.cover = rep(NA, num_levels),
  b1.truth = b1.truth
)
```

```{r outline1b-setup}
set.seed(721226) ## set seed so your findings are reproducible

num_reps <- 500 ## turn into a variable so we can easily change it
sample_size <- 100 ## turn into a variable so we can easily change it

b1.truth <- c(0.1, 0.2, 0.5, 1) ## possible scenarios

num_levels <- length(b1.truth) ## how many scenarios

## create a space to store estimates from each scenario
sim_study_output <- data.frame(
  b1.est = rep(NA, num_levels),
  b1.cover = rep(NA, num_levels),
  b1.truth = b1.truth
)
```

```{r, outline1b, exercise = T}
for (i in 1:num_levels) {
  sim_study_output[i, 1:2] <- simulate.est(
    n.sims = num_reps,
    n = sample_size,
    b0 = 2.80, b1 = b1.truth[i], residual_se = 0.74
  )
  ## only overwrite the first two columns
  ## same scenario except each time we change b1
}


sim_study_output

ggplot(sim_study_output, aes(x = b1.truth, y = (b1.est-b1.truth)/b1.truth)) +
  geom_point() +
  geom_line() +
  labs(x = "Slope Coefficient (truth)", y = "Scaled Bias") +
  ggtitle("Bias across Effect Sizes") +
  theme_minimal(base_size = 20)

ggplot(sim_study_output, aes(x = b1.truth, y = b1.cover)) +
  geom_point() +
  geom_line() +
  geom_hline(yintercept = 0.95) +
  labs(x = "Slope Coefficient (truth)", y = "Coverage for a 95% Interval") +
  ggtitle("Coverage across Effect Sizes") +
  theme_minimal(base_size = 20)
```

We can plot the scaled bias as a function of the slope coefficient. Why do we scale the bias? We want to know how far off is considered "a lot" with respect to the original effect size. 

We can also plot the coverage and compare it to what we expect (here 0.95). At first this might look like the coverge fluctuates wildly, but take a closer look at the y-axis scale. Every situation is very close to the "correct" coverage.

## Outline of a Simulation Study - Changing Two Parameters

What if we want to change two parameters. Now we need all combinations of pairs of parameters. This can add up quickly so be strategic about the combinations you are interested in.

```{r outline2, exercise = T}
set.seed(721226) ## set seed so your findings are reproducible

num_reps <- 500 ## turn into a variable so we can easily change it

sample_size <- c(50, 100, 150) ## possible scenarios
b1.truth <- c(0.1, 0.2, 0.5, 1) ## possible scenarios

num_levels <- length(b1.truth) * length(sample_size) ## how many scenarios

all_scenarios <- expand.grid(sample_size = sample_size, b1.truth = b1.truth)
## get all possible combinations of these two parameters
head(all_scenarios)
dim(all_scenarios)

## create a space to store estimates from each scenario
sim_study_output <- data.frame(
  b1.est = rep(NA, num_levels),
  b1.cover = rep(NA, num_levels),
  b1.truth = as.factor(all_scenarios$b1.truth),
  sample_size = all_scenarios$sample_size

)
## the as.factor lets R know that we want this to be a category, useful for plotting later
```

```{r, outline2b-setup}
set.seed(721226) ## set seed so your findings are reproducible

num_reps <- 500 ## turn into a variable so we can easily change it

sample_size <- c(50, 100, 150) ## possible scenarios
b1.truth <- c(0.1, 0.2, 0.5, 1) ## possible scenarios

num_levels <- length(b1.truth) * length(sample_size) ## how many scenarios

all_scenarios <- expand.grid(sample_size = sample_size, b1.truth = b1.truth)


## create a space to store power from each scenario
sim_study_output <- data.frame(
  b1.est = rep(NA, num_levels),
  b1.cover = rep(NA, num_levels),
  b1.truth = as.factor(all_scenarios$b1.truth),
  sample_size = all_scenarios$sample_size

)
```

Now we are interested in the relationship between sample size and power for different scenarios. We can plot the power as a function of the sample size and denote the scenarios with different colors.



```{r, outline2b, exercise = T}
for (i in 1:num_levels) {
  sim_study_output[i, 1:2] <- simulate.est(
    n.sims = num_reps,
    n = all_scenarios$sample_size[i],
    b0 = 2.80, b1 = all_scenarios$b1.truth[i], residual_se = 0.74
  )
  ## only overwrite the first two columns
  ## same scenario except each time we change b1 and sample size
}


sim_study_output

ggplot(sim_study_output, aes(x = sample_size, y = (b1.est-as.numeric(b1.truth))/as.numeric(b1.truth), col = b1.truth)) +
  geom_point() +
  geom_line() +
  labs(x = "Sample Size", y = "Scaled Bias") +
  ggtitle("Bias When Varying Effect Size \n and Sample Size") +
  theme_minimal(base_size = 20)
## the \n adds a line break in the title
## note we need b1.truth to be numeric to do calculations with it but a factor to color by it

ggplot(sim_study_output, aes(x = sample_size, y = b1.cover, col = b1.truth)) +
  geom_point() +
  geom_line() +
  geom_hline(yintercept = 0.95) +
  labs(x = "Sample Size", y = "Coverage for a 95% Interval") +
  ggtitle("Coverage When Varying \n Effect Size \n and Sample Size") +
  theme_minimal(base_size = 20)
```

## Outline of a Simulation Study - Changing Three Parameters

What if we want to change three parameters? Now we need all combinations of triplets of parameters. Again this can add up quickly so be strategic about the combinations you are interested in. To do 500 replications for 27 scenarios takes about a minute and a half. Here we will cut down the number of replications to 100, so we have to wait less than 30 seconds.

```{r outline3, exercise = T}
set.seed(721226) ## set seed so your findings are reproducible

num_reps <- 100 ## turn into a variable so we can easily change it

sample_size <- c(50, 100, 150) ## possible scenarios
b1.truth <- c(0.1, 0.5, 1) ## possible scenarios
residual_se <- c(0.2, 0.5, 0.75)

num_levels <- length(b1.truth) * length(sample_size) * length(residual_se) ## how many scenarios

all_scenarios <- expand.grid(sample_size = sample_size, b1.truth = b1.truth, residual_se = residual_se)
## get all possible combinations of these two parameters
head(all_scenarios)
dim(all_scenarios)

## create a space to store power from each scenario
sim_study_output <- data.frame(
  b1.est = rep(NA, num_levels),
  b1.cover = rep(NA, num_levels),
  b1.truth = as.factor(all_scenarios$b1.truth),
  sample_size = all_scenarios$sample_size,
  residual_se = as.factor(all_scenarios$residual_se)
)
## the as.factor lets R know that we want this to be a category, useful for plotting later
```

```{r outline3b-setup}
set.seed(721226) ## set seed so your findings are reproducible

num_reps <- 500 ## turn into a variable so we can easily change it

sample_size <- c(50, 100, 150) ## possible scenarios
b1.truth <- c(0.1, 0.5, 1) ## possible scenarios
residual_se <- c(0.2, 0.5, 0.75)

num_levels <- length(b1.truth) * length(sample_size) * length(residual_se) ## how many scenarios

all_scenarios <- expand.grid(sample_size = sample_size, b1.truth = b1.truth, residual_se = residual_se)

## create a space to store power from each scenario
sim_study_output <- data.frame(
  b1.est = rep(NA, num_levels),
  b1.cover = rep(NA, num_levels),
  b1.truth = as.factor(all_scenarios$b1.truth),
  sample_size = all_scenarios$sample_size,
  residual_se = as.factor(all_scenarios$residual_se)
)
## the as.factor lets R know that we want this to be a category, useful for plotting later
```


```{r outline3b, exercise = T}
for (i in 1:num_levels) {
  sim_study_output[i, 1:2] <- simulate.est(
    n.sims = num_reps,
    n = all_scenarios$sample_size[i],
    b0 = 2.80, b1 = all_scenarios$b1.truth[i], residual_se = all_scenarios$residual_se[i]
  )
  ## only overwrite the first two columns
  ## same scenario except each time we change b1, sample size, and residual standard error
}


sim_study_output

ggplot(sim_study_output, aes(x = sample_size, y = (b1.est - as.numeric(b1.truth))/as.numeric(b1.truth), col = b1.truth)) +
  geom_point() +
  geom_line() +
  facet_wrap(~residual_se) +
  labs(x = "Sample Size", y = "Scaled Bias") +
  ggtitle("Bias When Varying Effect Size \n and Sample Size") +
  theme_minimal(base_size = 20)
## the \n adds a line break in the title
## the facet_wrap makes a different plot of the same form for each of the specified categories

ggplot(sim_study_output, aes(x = sample_size, y = b1.cover, col = b1.truth)) +
  geom_point() +
  geom_line() +
  geom_hline(yintercept = 0.95) +
  facet_wrap(~residual_se) +
  labs(x = "Sample Size", y = "Coverage for a 95% Interval") +
  ggtitle("Coverage When Varying \n Effect Size \n and Sample Size") +
  theme_minimal(base_size = 20)
```

Now we are interested in the relationship between sample size and power for different scenarios that vary on two other parameters. We can plot the power as a function of the sample size and denote the scenarios with different colors and across multiple panels or "facets".

## Project Preview

Each project group will use the same number of replications, the same values the intercept for the regression line, the same sample sizes (multiple, across x-axis in result plots), the same slope coefficients for the regression line (multiple, color in result plots) and the same number of levels of misspecification (multiple, facets in result plots). You will be responsible for specifying what those misspecification levels look like. The residual standard error will take different forms depending on the misspecification scenario you are in.

* * *

This lab uses materials from [A. Hales](https://osf.io/rzbyj/) and various Open Intro labs and was adapted and learnr-ified by S. Stoudt.
