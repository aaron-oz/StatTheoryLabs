---
title: "Resampling Methods"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
knitr::opts_chunk$set(echo = FALSE)
library(learnrhash)
library(tidyverse)
library(gradethis)
library(infer)
tutorial_options(
  # use gradethis for checking
  exercise.checker = gradethis::grade_learnr
  )
knitr::opts_chunk$set(echo = FALSE)
set.seed(113877)
xs <- rnorm(n=100, mean = 5, sd = 1)
xs <- data.frame (x = xs)

theta_hat_100 = exp(mean(xs))

cal = rnorm(100, 100, 20)
flavor = c(rep("chocolate", 30), rep("vanilla", 70))

data = cbind.data.frame(cal = cal, flavor = flavor)

head(data)
```


## Some logistics for Lab 3

You should have a template.Rmd in your project. Open it, copy and paste it into a new Rmd file and proceed (in the top left corner, there is a button with a white square and a green plus sign icon, then choose the RMarkdown option). This tutorial will intersperse lab questions with some code chunks that you will interact with as part of the assignment. As you work your way through this tutorial, answer the questions in your own RMarkdown document. Make sure to label them and use formatting to make it straightforward to read. Your own code and text will be intermingled. 

## Sampling v. Bootstrap Distributions

In this section you will compare the 'true' sampling distribution of a statistic to the nonparametric bootstrap distribution.

## Lab Question #1


Let $X_1, X_2, ..., X_n \sim^{iid} N(\mu, 1)$ and $\theta = e^\mu$. Consider $\hat{\theta}_n$.

**a.)** Create a data set named `xs` of $n = 100$ observations from the above distribution using $\mu = 5$.

```{r generate-data, exercise = T}
xs <- rnorm(n=100, mean = 5, sd = 1)
xs <- data.frame (x = xs)

```

**b.)** What is the general form of the plug-in estimator of $\theta$? What is the estimate of $\hat{\theta}_n$ based on your data?

**c.)** Based on the pseudocode we wrote in class build your bootstrap distribution of $\hat{\theta}_n$ ($B = 10000$). There is a package in R that implements the bootstrap for many different scenarios called `infer`. 

**d.)**
Use this distribution to get $se_{boot}$ and three 95% confidence intervals for $\theta$ (normal interval, bootstrap percentile interval, bootstrap pivotal interval).

You can use the following interactive components to check your work. If you get stuck on the bootstrap implementation, you can answer the rest of the sub-questions in Lab Question 1 Part I using the results in the tutorial in the meantime until you can get some help from me.

## $se_{boot}$ checker

```{r se-check, exercise = T}
boot_dist <- xs %>%
  specify(response = x) %>%
  generate(reps = 10000, type = "bootstrap") %>%
  calculate(stat = "mean")

sd(exp(boot_dist$stat))

```

## Percentile Bootstrap Checker

```{r bootstrap-check1, exercise = T}
boot_dist <- xs %>%
  specify(response = x) %>%
  generate(reps = 10000, type = "bootstrap") %>%
  calculate(stat = "mean")

percentile_ci <- get_ci(boot_dist, level = 0.95)

exp(percentile_ci) 
## Make sure you understand why I can exponentiate the percentiles and it is the same as first exponentiated everything and then taking the percentile

visualize(boot_dist) +
  shade_confidence_interval(endpoints = exp(percentile_ci))

```

## Bootstrap Pivotal Checker

```{r bootstrap-check2, exercise = T}
boot_dist <- xs %>%
  specify(response = x) %>%
  generate(reps = 10000, type = "bootstrap") %>%
  calculate(stat = "mean")

lb <- 2 * theta_hat_100 - quantile(exp(boot_dist$stat), 0.975)
ub <- 2 * theta_hat_100 - quantile(exp(boot_dist$stat), 0.025)

lb
ub

# Note: The calculation of theta_hat_100 is hidden from you as this is question 1b.
```

## Lab Question #1 cont.

**e.)** Plot a histogram of the bootstrap relications and describe the distribution. This is the bootstrap distribution of $\hat{\theta}_n$.

**f.)** Plot a histogram of the 'true' sampling distribution and describe the distribution. Hint: The sampling distribution is defined as the distribution of $\hat{\theta}_n$ calculated from every possible sample of the same size from the population. For simplicity, build the sampling distribution using 10000 random samples from the population. 

**g.)** Compare the two distributions. 


## Lab Question #2

Consider a population that has a gamma distribution with parameters $\alpha = 5$ and $\beta =4$. Recall that the gamma function in R requires the parameteriazation $1/\beta$.

**a.)** Describe the approximate sampling distribution for the mean shown below.

```{r, gamma1, exercise = T}
n <- 200
xbars <- rep(NA, n)

for (i in 1:n) {
  dat <- rgamma(n, 5, 1 / 4)
  xbars[i] <- mean(data)
}

xbars <- data.frame(x = xbars)

ggplot(xbars, aes(x = x)) +
  geom_histogram() +
  theme_minimal()

```

Note: We can upgrade our basic histograms so that they look nicer using `ggplot`.  

With `ggplot()`:

- The first argument is always the dataset. 
- Next, you provide the variables from the dataset to be assigned to `aes`thetic elements of the plot, e.g. the x and the y axes. 
- Finally, you use another layer, separated by a `+` to specify the `geom`etric object for the plot. Since we want a histogram, we use `geom_histogram()`. Other geometries we will use later are `geom_point()` and `geom_line()`.

`theme_minimal()` provides a style to the overall plot type. Try removing it to see what a default ggplot histogram looks like. 

For more `ggplot` specifications, check out the [cheat sheet](https://www.maths.usyd.edu.au/u/UG/SM/STAT3022/r/current/Misc/data-visualization-2.1.pdf).


**b.)** Find the mean and standard deviation of the sample created below. Find the bootstrap mean and standard error of the bootstrap distribution for your sample.

```{r, gamma2, exercise = T}
samp <- rgamma(n = 200, 5, 1 / 4)

mean(___)
sd(___)

samp <- data.frame(x = samp)
boot_dist <- samp %>%
  specify(response = x) %>%
  generate(reps = 10000, type = "bootstrap") %>%
  calculate(stat = "mean")

visualize(boot_dist)

mean(___$stat)
sd(___$stat)
```

**c.)** Compare the bootstrap distribution to the approximate sampling distribution by answering the following questions:

- What is the population mean and standard deviation?

- What is the sample mean and standard deviaton?

- What is the mean and standard deviation of the sampling distribution of $\bar{X}$?

- What is the mean and standard deviation of the bootstrap distribution of $\bar{X}$?

**d.)** Adjust the sample size to $n=10$ in the learnr tutorial and compare the bootstrap distribution to the approximate sampling distribution by answering the following questions:

- What is the population mean and standard deviation?

- What is the sample mean and standard deviaton?

- What is the mean and standard deviation of the sampling distribution of $\bar{X}$?

- What is the mean and standard deviation of the bootstrap distribution of $\bar{X}$?

**e.)** What is the effect of sample size on the bootstrap distribution?


## Lab Question #3 - The bootstrap standard error

In this exercise, we will investiage how accurate the bootstrap estimate of the standard error is when the sample size is small.

Let $X_1, X_2, ..., X_n \sim_{iid} N(\theta, 1)$. The plug-in estimate of $\theta$ is $\hat{\theta}_n = \bar{X}$. 

**a.)** Find an exact expression for the standard error of $\hat{\theta}_n$ and call this $se$. 

**b.)** Now take $\theta = 0$, $n=5$ and conduct a simulation. In this simulation, you will create 100 bootstrap distributions. Each time you simulate a bootstrap distribution, estimate the standard error. To keep this mangeable, use B = 200 in the bootstrap and use 100 simulations. You will then get 100 bootstrap standard errors, $se_1, ..., se_{100}$. Hint: This will require a double for loop, with the outer loop for the 100 simulations and the inner loop for computing the 200 bootstrap replications.

**c.)** To assess the accuracy of the bootstrap, compute the mean of $\frac{|se_1 - se|}{se}, ... \frac{|se_{100} - se|}{se}$. What is your conclusion about the accuracy of the bootstrap standard error?

**d.)** Repeat for $n=50$ and comment on the accuracy.

## Lab Question #4 - Two-sample bootstrap

In general, bootstrapping sampling should mimic how the data were sampled. For example, if the data correspond to independent samples from two distinct populations, we should draw two samples in that way. With the two resamples, we proceed by computing the statistic comparing the resamples, as we normally would, such as difference in means or proportions. The `infer` package as of now, actually does not implement their two-sample bootstrap this way (see [here](https://github.com/tidymodels/infer/issues/245)), so we would need to code it from scratch to make it happen.

Here is the pseudocode for this type of bootstrap:

1. Draw a resample of size $m$ with replacement from the first sample and a separate resample of size $n$ from the second sample. 

2. Compute a statistic that compares the two groups.

3. Repeat this resampling process $B$ times.

4. Construct the bootstrap distribution of the statistic.

Hint: This all happens in a single loop.

**a.)** The data set `IceCream` (provided on Moodle) contains calorie information for a sample of brands of chocolate and vanilla ice cream. Use a 95% bootstrap percentile interval to determine whether or not there is a difference in the average number of calories. Include a histogram of your bootstrap distribution.

**b.)** Would you expect the 95% bootstrap normal interval to be similar to that in (a)? Why or why not?

In class we wrote code to perform a permutation test. It looked like this (using some fake data to illustrate).

```{r perm-data, exercise = T}
cal = rnorm(100, 100, 20)
flavor = c(rep("chocolate", 30), rep("vanilla", 70))

data = cbind.data.frame(cal = cal, flavor = flavor)

head(data)
```

```{r perm, exercise = T}
mean.diff <- rep(NA, 1000)

for (i in 1:1000) {
  perm <- sample(data$flavor, nrow(data), replace = F)
  mean.diff[i] <- mean(data$cal[perm == "chocolate"]) - mean(data$cal[perm == "vanilla"])
}

mean.diff <- data.frame(x = mean.diff)

ggplot(mean.diff, aes(x = x)) +
  geom_histogram() +
  theme_minimal()
```

**c.)** Determine whether or not there is a difference in the average number of calories for the two types of ice cream using a permutation test. Do you reach the same conclusion?




## Deliverables

Submit your R Markdown document and knitted file to Moodle as:

LastName-LastName-LastName-L-03.Rmd  (add a third last name if applicable)

LastName-LastName-LastName-L-03.html

To get these files onto your own computer, look in the "Files" pane in the bottom right. Check the boxes next to the two files you want to export, click the "More" button (with a little blue gear), click "Export". Make sure you are exporting the files to a place where you can find them on your own computer. 

*Due*: Wednesday, October 20th at 5 PM





* * *

This lab was adapted from a lab created by A. Flynt and was learnr-ified by S. Stoudt.
